from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
import os
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# FastAPIã‚¢ãƒ—ãƒªã®ä½œæˆ
app = FastAPI()

# CORSè¨­å®šï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://ai-kondate-app2.vercel.app",  # â†ã“ã“ãŒä»Šä½¿ã£ã¦ã„ã‚‹Vercelã®URL
        "https://ai-kondate-app.vercel.app",   # â†æ—§URLï¼ˆå¿…è¦ãªã‚‰æ®‹ã™ï¼‰
        "http://localhost:3000",               # â†ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
        "http://127.0.0.1:3000"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‹
class IngredientInput(BaseModel):
    ingredients: str

# å‹•ä½œç¢ºèªç”¨ã®ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
def read_root():
    return {"message": "AIçŒ®ç«‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒèµ·å‹•ä¸­ã§ã™ğŸ³"}

# ãƒ¬ã‚·ãƒ”ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/recipe")
async def get_recipe(input: IngredientInput):
    prompt = f"{input.ingredients} ã‚’ä½¿ã£ãŸç°¡å˜ãªæ–™ç†ã‚’1ã¤æ•™ãˆã¦ã€‚èª¿ç†æ™‚é–“ã¨è¶³ã‚Šãªã„ææ–™ã‚‚æ•™ãˆã¦ã€‚"

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )

    return {"recipe": response.choices[0].message.content}

